{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import Essential Python Libraries\n",
    "\n",
    "# Dependencies : Tensorflow , Pandas , NumPy and Sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "from tensorflow.keras.layers import LSTMCell\n",
    "from tensorflow.contrib.rnn.python.ops import core_rnn\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Appreciate some randomness\n",
    "tf.set_random_seed(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tuning the Hyperparameters\n",
    "\n",
    "lr = 0.005    # learning rate\n",
    "training_iters = 100000   # training epochs\n",
    "batch_size = 50         # mini batch size\n",
    "n_inputs = 30\n",
    "n_steps = 6   # time steps\n",
    "n_hidden_units = 256 # neurons in hidden layer\n",
    "n_classes  = 2         # number of classes [recall , non-recall ]\n",
    "num_layers =4     # number of layers in the hidden network\n",
    "keep_prob  =0.8       # Dropout probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\MasterThesis\\v1.0\\pupil_dataset.csv\")\n",
    "labels = df['labels']\n",
    "df = df.drop(df.columns[-1], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset=np.array(data)\n",
    "N = dataset.shape[0]\n",
    "X_train = dataset[:,0:dataset.shape[1]-1]\n",
    "# Targets have labels 1-indexed. We subtract one for 0-indexed\n",
    "y_train = dataset[:,dataset.shape[1]-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(dataset.shape[0],n_steps,n_inputs)\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function for one hot encoding\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N, 2))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/Users/brad/Documents/AkshayNew/sampleData/testingData.dat\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_test=df_test\n",
    "testset=np.array(data_test)\n",
    "M = testset.shape[0]\n",
    "X_test = testset[:,0:testset.shape[1]-1]\n",
    "\n",
    "# Targets have labels 1-indexed. We subtract one for 0-indexed\n",
    "y_test = testset[:,testset.shape[1]-1]\n",
    "\n",
    "y_test=y2indicator(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "std_scale2 = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = std_scale2.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test=X_test.reshape(testset.shape[0],n_steps,n_inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One Hot Encoded : Targets  - Recall & Non - Recall\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "\n",
    "# Tensorflow Placeholders\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_steps,n_inputs],name='Inputs')\n",
    "y = tf.placeholder(tf.float32, [None,n_classes],name='Labels')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define weights and Biases\n",
    "\n",
    "with tf.name_scope('Weights'):\n",
    "\n",
    "    weights = {\n",
    "    # (5,128)\n",
    "    'in': tf.Variable(tf.truncated_normal([n_inputs, n_hidden_units]),name = 'W_in'),\n",
    "\n",
    "    # (128, 2)\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_units, n_classes]),name='W_out')\n",
    "\n",
    "    }\n",
    "    tf.summary.histogram('weights_in', weights['in'])\n",
    "    tf.summary.histogram('weights_out', weights['out'])\n",
    "with tf.name_scope('Biases'):\n",
    "\n",
    "    biases = {\n",
    "    # (128, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ]),name='b_in'),\n",
    "    # (2, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]),name='b_out')\n",
    "\n",
    "    }\n",
    "    tf.summary.histogram('biases_in', biases['in'])\n",
    "    tf.summary.histogram('biases_out', biases['out']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a costumizable RNN function\n",
    "\n",
    "def RNN(X, weights, biases):\n",
    "    # hidden layer for input to cell\n",
    "\n",
    "    X = tf.reshape(X, [-1, n_inputs])\n",
    "\n",
    "\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "\n",
    "    # basic LSTM Cell integrated with a Dropout Facility.\n",
    "\n",
    "    cell=tf.contrib.rnn.DropoutWrapper(LSTMCell(n_hidden_units),output_keep_prob=keep_prob)\n",
    "\n",
    "    # Feed single cell to Multi Dimensional RNN to add layers\n",
    "\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([cell]*num_layers)\n",
    "\n",
    "    # lstm cell is divided into two parts (c_state, h_state)\n",
    "\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    # Use a dynamic RNN\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)\n",
    "\n",
    "    outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "\n",
    "    results = tf.matmul(outputs[-1], weights['out']) + biases['out']    # shape = (128, 10)\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to load mini -batch operations\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating Loss function and its properties\n",
    "\n",
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    with tf.variable_scope(\"Softmax_params\"):\n",
    "\n",
    "        beta = 0.01\n",
    "        pred = RNN(x, weights, biases)\n",
    "        # Cost Function\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y,name='logits'))\n",
    "        # Loss function using L2 Regularization\n",
    "        regularizer = tf.nn.l2_loss(weights['in'])\n",
    "        cost = tf.reduce_mean(cost + beta * regularizer)\n",
    "        correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        h1 = tf.summary.scalar('accuracy',accuracy)\n",
    "        h2 = tf.summary.scalar('cost', cost)\n",
    "        softmaxed_logits = tf.nn.softmax(pred)\n",
    "        auc=tf.contrib.metrics.streaming_auc(\n",
    "                              predictions=softmaxed_logits,\n",
    "                              labels=y,\n",
    "                              curve='ROC')\n",
    "with tf.name_scope(\"Optimizer\") as scope:\n",
    "    train_op = tf.train.AdamOptimizer(lr).minimize(cost)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_xs, batch_ys = next_batch(batch_size,X_train,y_train)\n",
    "batch_xs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Running the Neural Network with Tensorflow Session\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #Final code for the TensorBoard\n",
    "\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    init=tf.global_variables_initializer()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = next_batch(batch_size,X_train,y_train)\n",
    "        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n",
    "        X_batch, y_batch = next_batch(batch_size,X_test,y_test)\n",
    "        X_batch = X_batch.reshape([batch_size, n_steps, n_inputs])\n",
    "        sess.run([train_op], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        })\n",
    "        if step %50 == 0:\n",
    "            cost_train,acc_train=sess.run([cost,accuracy], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "            })\n",
    "\n",
    "            #Evaluate validation performance [Testing Data]\n",
    "\n",
    "            test_auc,cost_val,summ,acc_val = sess.run([auc,cost,merged,accuracy],feed_dict = {x: X_batch, y: y_batch})\n",
    "            print('At %5.0f/%5.0f: Train COST %5.3f -- Test COST %5.3f -- Test Accuracy %5.3f ' %(step,training_iters,cost_train,cost_val,acc_val))\n",
    "\n",
    "\n",
    "            #sess.run(tf.local_variables_initializer())\n",
    "            #test_auc = sess.run(auc)\n",
    "\n",
    "            print(test_auc)\n",
    "            writer.add_summary(summ, step)\n",
    "            writer.flush()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print('Done !')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
